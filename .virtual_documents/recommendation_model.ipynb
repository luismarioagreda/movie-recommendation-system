





# def transform_genres(genres_str):
#     """
#     Transform the genres string into a multi-hot encoded vector.
    
#     Args:
#         genres_str (str): A string containing genres separated by '|'.
        
#     Returns:
#         dict: A dictionary where keys are genres and values are 1 (present) or 0 (absent).
#     """
    
#     genres = genres_str.split('|')
#     genres_dict = defaultdict(int)
#     for genre in genres:
#         genres_dict[genre] = 1
#     return genres_dict

# def multi_hot_encode_genres(movies_df):
#     """
#     Perform multi-label binarization on the genres column of the movies DataFrame.
    
#     Args:
#         movies_df (pd.DataFrame): The movies DataFrame containing the 'genres' column.
        
#     Returns:
#         pd.DataFrame: The transformed DataFrame with multi-hot encoded genres.
#     """
    
#     # Identify all unique genres
#     all_genres = set()
#     for genres_str in movies_df['genres']:
#         all_genres.update(genres_str.split('|'))
    
#     # Create a new DataFrame with movie ID, title, and binary columns for each genre
#     new_df = movies_df[['movieId', 'title']].copy()
#     for genre in all_genres:
#         new_df[genre] = 0
    
#     # Multi-hot encode the genres
#     for index, row in movies_df.iterrows():
#         genres_dict = transform_genres(row['genres'])
#         for genre, value in genres_dict.items():
#             new_df.at[index, genre] = value
    
#     return new_df

# # Perform multi-label binarization
# movies_multilabel = multi_hot_encode_genres(movies)
# print(movies_multilabel.head())


import pandas as pd
# import numpy as np
# import sklearn as sk

movies = pd.read_csv('data/movie.csv')
ratings = pd.read_csv('data/rating.csv')

# g_tags = pd.read_csv('data/genome_tags.csv', nrows=5)
# tags = pd.read_csv('data/tag.csv', nrows=5)

# g_scores = pd.read_csv('data/genome_scores.csv', nrows=0)
# links = pd.read_csv('data/link.csv', nrows=0)






def check_missing(df):
    print(df.isnull().sum())
    print('-'*25)
    
def check_duplicates(df):
    print(df.duplicated().sum())
    
# Check missing values
check_missing(movies)
check_missing(ratings)
print('*'*50)

# Checking duplicates
check_duplicates(movies)
check_duplicates(ratings)
print('*'*50)

# 5 first rows of the dataframe
print(movies.head())


import re

def clean_title(title):
    return re.sub("[^a-zA-Z0-9 ]", "", title)

movies['clean_title'] = movies['title'].apply(clean_title)


# Building search function
from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(ngram_range=(1, 2))

tfidf = vectorizer.fit_transform(movies['clean_title'])


from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

def search(title):
    title = clean_title(title)
    query_vec = vectorizer.transform([title])
    similarity = cosine_similarity(query_vec, tfidf).flatten()
    indices = np.argpartition(similarity, -5)[-5:]
    results = movies.iloc[indices][::-1]
    return results

search('Harry Potter')


import ipywidgets as widgets
from IPython.display import display

movie_input = widgets.Text(
    value="Toy Story", 
    description="Movie Title: ",
    disabled=False
)
movie_input



